{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Training Poker Using RLLib*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaronedwards/Documents/Projects/RL_Poker_Env/poker_env.py:10: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
      "  from collections import Iterable\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from poker_env import PokerEnv\n",
    "from agents.random_policy import RandomActions\n",
    "from agents.heuristic_policy import HeuristicPolicy\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.rllib.algorithms.a3c import A3C\n",
    "from ray.rllib.algorithms.sac import SAC\n",
    "from ray.rllib.algorithms.dqn import DQN\n",
    "from gym import spaces\n",
    "import mpu\n",
    "import numpy as np\n",
    "import ray\n",
    "from ray.rllib.models import MODEL_DEFAULTS\n",
    "from ray.rllib.policy.policy import PolicySpec\n",
    "from ray.tune.registry import register_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Rllib, a policy function needs to be passed to map agent IDs to the policy to use. We also create and register the learning environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_policy(agent_id, episode, **kwargs):\n",
    "    if agent_id == 0:\n",
    "        return \"a3c\"\n",
    "    elif agent_id == 1:\n",
    "        return \"sac\"\n",
    "    elif agent_id == 2:\n",
    "        return \"dqn\"\n",
    "    elif agent_id == 3:\n",
    "        return \"ppo\"\n",
    "    return \"learned4\"\n",
    "\n",
    "def env_creator(config):\n",
    "    env = PokerEnv(select_policy, config)\n",
    "    return env\n",
    "\n",
    "register_env(\"poker\", lambda config: env_creator(config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The config describes all aspects of the training. A full list of the parameters is found here: https://github.com/ray-project/ray/blob/master/rllib/algorithms/algorithm_config.py \n",
    "\n",
    "In this example, we have used a default config that runs the PPO algorithm. Other heuristic agents have been defined that will play the game with the single learning agent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 14:37:06,517\tWARNING ppo.py:351 -- `train_batch_size` (4000) cannot be achieved with your other settings (num_workers=8 num_envs_per_worker=1 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 500.\n",
      "2022-11-10 14:37:09,920\tINFO worker.py:1528 -- Started a local Ray instance.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76323)\u001b[0m /Users/aaronedwards/Documents/Projects/RL_Poker_Env/poker_env.py:10: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76323)\u001b[0m   from collections import Iterable\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76325)\u001b[0m /Users/aaronedwards/Documents/Projects/RL_Poker_Env/poker_env.py:10: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76325)\u001b[0m   from collections import Iterable\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76330)\u001b[0m /Users/aaronedwards/Documents/Projects/RL_Poker_Env/poker_env.py:10: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76330)\u001b[0m   from collections import Iterable\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76327)\u001b[0m /Users/aaronedwards/Documents/Projects/RL_Poker_Env/poker_env.py:10: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76327)\u001b[0m   from collections import Iterable\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76328)\u001b[0m /Users/aaronedwards/Documents/Projects/RL_Poker_Env/poker_env.py:10: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76328)\u001b[0m   from collections import Iterable\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76324)\u001b[0m /Users/aaronedwards/Documents/Projects/RL_Poker_Env/poker_env.py:10: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76324)\u001b[0m   from collections import Iterable\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76329)\u001b[0m /Users/aaronedwards/Documents/Projects/RL_Poker_Env/poker_env.py:10: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76329)\u001b[0m   from collections import Iterable\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76326)\u001b[0m /Users/aaronedwards/Documents/Projects/RL_Poker_Env/poker_env.py:10: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76326)\u001b[0m   from collections import Iterable\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76323)\u001b[0m 2022-11-10 14:37:22,378\tERROR worker.py:763 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=76323, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f7c857459d0>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76323)\u001b[0m   File \"/Users/aaronedwards/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 625, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76323)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76323)\u001b[0m   File \"/Users/aaronedwards/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1899, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76323)\u001b[0m     self.policy_map.create_policy(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76323)\u001b[0m   File \"/Users/aaronedwards/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/policy/policy_map.py\", line 132, in create_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76323)\u001b[0m     _class = get_tf_eager_cls_if_necessary(policy_cls, merged_config)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76323)\u001b[0m   File \"/Users/aaronedwards/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/utils/tf_utils.py\", line 246, in get_tf_eager_cls_if_necessary\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76323)\u001b[0m     raise ImportError(\"Could not import tensorflow!\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76323)\u001b[0m ImportError: Could not import tensorflow!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76325)\u001b[0m 2022-11-10 14:37:22,378\tERROR worker.py:763 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=76325, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7fd081f849a0>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76325)\u001b[0m   File \"/Users/aaronedwards/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 625, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76325)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76325)\u001b[0m   File \"/Users/aaronedwards/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1899, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76325)\u001b[0m     self.policy_map.create_policy(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76325)\u001b[0m   File \"/Users/aaronedwards/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/policy/policy_map.py\", line 132, in create_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76325)\u001b[0m     _class = get_tf_eager_cls_if_necessary(policy_cls, merged_config)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76325)\u001b[0m   File \"/Users/aaronedwards/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/utils/tf_utils.py\", line 246, in get_tf_eager_cls_if_necessary\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76325)\u001b[0m     raise ImportError(\"Could not import tensorflow!\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76325)\u001b[0m ImportError: Could not import tensorflow!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76330)\u001b[0m 2022-11-10 14:37:22,378\tERROR worker.py:763 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=76330, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f8f5ef849a0>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76330)\u001b[0m   File \"/Users/aaronedwards/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 625, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76330)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76330)\u001b[0m   File \"/Users/aaronedwards/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1899, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76330)\u001b[0m     self.policy_map.create_policy(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76330)\u001b[0m   File \"/Users/aaronedwards/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/policy/policy_map.py\", line 132, in create_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76330)\u001b[0m     _class = get_tf_eager_cls_if_necessary(policy_cls, merged_config)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76330)\u001b[0m   File \"/Users/aaronedwards/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/utils/tf_utils.py\", line 246, in get_tf_eager_cls_if_necessary\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76330)\u001b[0m     raise ImportError(\"Could not import tensorflow!\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76330)\u001b[0m ImportError: Could not import tensorflow!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76327)\u001b[0m 2022-11-10 14:37:22,378\tERROR worker.py:763 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=76327, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7fe58e7449d0>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76327)\u001b[0m   File \"/Users/aaronedwards/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 625, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76327)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76327)\u001b[0m   File \"/Users/aaronedwards/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1899, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76327)\u001b[0m     self.policy_map.create_policy(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76327)\u001b[0m   File \"/Users/aaronedwards/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/policy/policy_map.py\", line 132, in create_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76327)\u001b[0m     _class = get_tf_eager_cls_if_necessary(policy_cls, merged_config)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76327)\u001b[0m   File \"/Users/aaronedwards/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/utils/tf_utils.py\", line 246, in get_tf_eager_cls_if_necessary\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76327)\u001b[0m     raise ImportError(\"Could not import tensorflow!\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76327)\u001b[0m ImportError: Could not import tensorflow!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76328)\u001b[0m 2022-11-10 14:37:22,378\tERROR worker.py:763 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=76328, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7fd9f6745970>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76328)\u001b[0m   File \"/Users/aaronedwards/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 625, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76328)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76328)\u001b[0m   File \"/Users/aaronedwards/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1899, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76328)\u001b[0m     self.policy_map.create_policy(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76328)\u001b[0m   File \"/Users/aaronedwards/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/policy/policy_map.py\", line 132, in create_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76328)\u001b[0m     _class = get_tf_eager_cls_if_necessary(policy_cls, merged_config)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76328)\u001b[0m   File \"/Users/aaronedwards/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/utils/tf_utils.py\", line 246, in get_tf_eager_cls_if_necessary\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76328)\u001b[0m     raise ImportError(\"Could not import tensorflow!\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76328)\u001b[0m ImportError: Could not import tensorflow!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76324)\u001b[0m 2022-11-10 14:37:22,379\tERROR worker.py:763 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=76324, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f91f7f449a0>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76324)\u001b[0m   File \"/Users/aaronedwards/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 625, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76324)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76324)\u001b[0m   File \"/Users/aaronedwards/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1899, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76324)\u001b[0m     self.policy_map.create_policy(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76324)\u001b[0m   File \"/Users/aaronedwards/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/policy/policy_map.py\", line 132, in create_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76324)\u001b[0m     _class = get_tf_eager_cls_if_necessary(policy_cls, merged_config)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76324)\u001b[0m   File \"/Users/aaronedwards/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/utils/tf_utils.py\", line 246, in get_tf_eager_cls_if_necessary\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76324)\u001b[0m     raise ImportError(\"Could not import tensorflow!\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76324)\u001b[0m ImportError: Could not import tensorflow!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76329)\u001b[0m 2022-11-10 14:37:22,378\tERROR worker.py:763 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=76329, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7fb3ee084a30>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76329)\u001b[0m   File \"/Users/aaronedwards/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 625, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76329)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76329)\u001b[0m   File \"/Users/aaronedwards/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1899, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76329)\u001b[0m     self.policy_map.create_policy(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76329)\u001b[0m   File \"/Users/aaronedwards/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/policy/policy_map.py\", line 132, in create_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76329)\u001b[0m     _class = get_tf_eager_cls_if_necessary(policy_cls, merged_config)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76329)\u001b[0m   File \"/Users/aaronedwards/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/utils/tf_utils.py\", line 246, in get_tf_eager_cls_if_necessary\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76329)\u001b[0m     raise ImportError(\"Could not import tensorflow!\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76329)\u001b[0m ImportError: Could not import tensorflow!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76326)\u001b[0m 2022-11-10 14:37:22,378\tERROR worker.py:763 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=76326, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7fd835745a00>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76326)\u001b[0m   File \"/Users/aaronedwards/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 625, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76326)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76326)\u001b[0m   File \"/Users/aaronedwards/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1899, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76326)\u001b[0m     self.policy_map.create_policy(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76326)\u001b[0m   File \"/Users/aaronedwards/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/policy/policy_map.py\", line 132, in create_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76326)\u001b[0m     _class = get_tf_eager_cls_if_necessary(policy_cls, merged_config)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76326)\u001b[0m   File \"/Users/aaronedwards/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/utils/tf_utils.py\", line 246, in get_tf_eager_cls_if_necessary\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76326)\u001b[0m     raise ImportError(\"Could not import tensorflow!\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76326)\u001b[0m ImportError: Could not import tensorflow!\n",
      "/Users/aaronedwards/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/algorithms/algorithm.py:1688: DeprecationWarning: invalid escape sequence \\|\n",
      "  \"\"\"Adds a new policy to this Algorithm.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Could not import tensorflow!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRayActorError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/algorithms/algorithm.py:524\u001b[0m, in \u001b[0;36mAlgorithm.setup\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 524\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers \u001b[38;5;241m=\u001b[39m \u001b[43mWorkerSet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv_creator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv_creator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_default_policy_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrainer_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_workers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogdir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogdir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;66;03m# WorkerSet creation possibly fails, if some (remote) workers cannot\u001b[39;00m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# be initialized properly (due to some errors in the RolloutWorker's\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;66;03m# constructor).\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/evaluation/worker_set.py:139\u001b[0m, in \u001b[0;36mWorkerSet.__init__\u001b[0;34m(self, env_creator, validate_env, policy_class, trainer_config, num_workers, local_worker, logdir, _setup)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_remote_workers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_workers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalidate_workers_after_construction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# Create a local worker, if needed.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# If num_workers > 0 and we don't have an env on the local worker,\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# get the observation- and action spaces for each policy from\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# the first remote worker (which does have an env).\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/evaluation/worker_set.py:490\u001b[0m, in \u001b[0;36mWorkerSet.add_workers\u001b[0;34m(self, num_workers, validate)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate:\n\u001b[0;32m--> 490\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforeach_worker\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_healthy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/evaluation/worker_set.py:620\u001b[0m, in \u001b[0;36mWorkerSet.foreach_worker\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    619\u001b[0m     local_result \u001b[38;5;241m=\u001b[39m [func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocal_worker())]\n\u001b[0;32m--> 620\u001b[0m remote_results \u001b[38;5;241m=\u001b[39m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremote\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremote_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m local_result \u001b[38;5;241m+\u001b[39m remote_results\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/_private/client_mode_hook.py:105\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/_private/worker.py:2291\u001b[0m, in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   2290\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2291\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[1;32m   2293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_individual_id:\n",
      "\u001b[0;31mRayActorError\u001b[0m: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=76329, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7fb3ee084a30>)\n  File \"/Users/aaronedwards/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 625, in __init__\n    self._build_policy_map(\n  File \"/Users/aaronedwards/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1899, in _build_policy_map\n    self.policy_map.create_policy(\n  File \"/Users/aaronedwards/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/policy/policy_map.py\", line 132, in create_policy\n    _class = get_tf_eager_cls_if_necessary(policy_cls, merged_config)\n  File \"/Users/aaronedwards/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/utils/tf_utils.py\", line 246, in get_tf_eager_cls_if_necessary\n    raise ImportError(\"Could not import tensorflow!\")\nImportError: Could not import tensorflow!",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 33\u001b[0m\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m MODEL_DEFAULTS\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfcnet_hiddens\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m512\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfcnet_activation\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m     10\u001b[0m config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     11\u001b[0m     PPOConfig()\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m#Each rollout worker uses a single cpu\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;241m.\u001b[39mframework(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     32\u001b[0m )\n\u001b[0;32m---> 33\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpoker\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/algorithms/algorithm_config.py:311\u001b[0m, in \u001b[0;36mAlgorithmConfig.build\u001b[0;34m(self, env, logger_creator)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logger_creator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger_creator \u001b[38;5;241m=\u001b[39m logger_creator\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malgo_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger_creator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogger_creator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/algorithms/algorithm.py:414\u001b[0m, in \u001b[0;36mAlgorithm.__init__\u001b[0;34m(self, config, env, logger_creator, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;66;03m# Initialize common evaluation_metrics to nan, before they become\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;66;03m# available. We want to make sure the metrics are always present\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;66;03m# (although their values may be nan), so that Tune does not complain\u001b[39;00m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;66;03m# when we use these as stopping criteria.\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_metrics \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepisode_reward_max\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mnan,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    411\u001b[0m     }\n\u001b[1;32m    412\u001b[0m }\n\u001b[0;32m--> 414\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger_creator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger_creator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;66;03m# Check, whether `training_iteration` is still a tune.Trainable property\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;66;03m# and has not been overridden by the user in the attempt to implement the\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;66;03m# algos logic (this should be done now inside `training_step`).\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/tune/trainable/trainable.py:161\u001b[0m, in \u001b[0;36mTrainable.__init__\u001b[0;34m(self, config, logger_creator, remote_checkpoint_dir, custom_syncer, sync_timeout)\u001b[0m\n\u001b[1;32m    159\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local_ip \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mget_node_ip_address()\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m setup_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m setup_time \u001b[38;5;241m>\u001b[39m SETUP_TIME_THRESHOLD:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/poker2/lib/python3.9/site-packages/ray/rllib/algorithms/algorithm.py:549\u001b[0m, in \u001b[0;36mAlgorithm.setup\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RayActorError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;66;03m# In case of an actor (remote worker) init failure, the remote worker\u001b[39;00m\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;66;03m# may still exist and will be accessible, however, e.g. calling\u001b[39;00m\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;66;03m# its `sample.remote()` would result in strange \"property not found\"\u001b[39;00m\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;66;03m# errors.\u001b[39;00m\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mactor_init_failed:\n\u001b[1;32m    542\u001b[0m         \u001b[38;5;66;03m# Raise the original error here that the RolloutWorker raised\u001b[39;00m\n\u001b[1;32m    543\u001b[0m         \u001b[38;5;66;03m# during its construction process. This is to enforce transparency\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;66;03m# - e.args[0].args[2]: The original Exception (e.g. a ValueError due\u001b[39;00m\n\u001b[1;32m    548\u001b[0m         \u001b[38;5;66;03m# to a config mismatch) thrown inside the actor.\u001b[39;00m\n\u001b[0;32m--> 549\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;66;03m# In any other case, raise the RayActorError as-is.\u001b[39;00m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    552\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[0;31mImportError\u001b[0m: Could not import tensorflow!"
     ]
    }
   ],
   "source": [
    "heuristic_observation_space = spaces.Dict({\n",
    "            \"hand\": spaces.Box(0, 1, shape=(24, )),\n",
    "            \"community\": spaces.Box(0, 1, shape=(24, ))\n",
    "        })\n",
    "action_space = spaces.Discrete(3)\n",
    "\n",
    "#Defines the learning models architecture. \n",
    "model = MODEL_DEFAULTS.update({'fcnet_hiddens': [512, 512], 'fcnet_activation': 'relu'})\n",
    "\n",
    "config = (\n",
    "    PPOConfig()\n",
    "    #Each rollout worker uses a single cpu\n",
    "    .rollouts(num_rollout_workers=8, num_envs_per_worker=1)\\\n",
    "    .training(train_batch_size=4000, gamma=0.99, model=model, lr=0.0004)\\\n",
    "    .environment(disable_env_checking=True)\\\n",
    "    .multi_agent(\n",
    "        policies={\n",
    "            #These policies thave pre-definded polices that dont learn.\n",
    "            \"a3c\": PolicySpec(config=A3C.get_default_config()),\n",
    "            \"sac\": PolicySpec(config=SAC.get_default_config()),\n",
    "            \"dqn\": PolicySpec(config=DQN.get_default_config()),\n",
    "            #Passing nothing causes this agent to deafult to using a PPO policy\n",
    "            \"ppo\": PolicySpec(\n",
    "                config={}\n",
    "            ),\n",
    "        },\n",
    "        policy_mapping_fn=select_policy,\n",
    "        policies_to_train=['a3c', 'sac', 'dqn', 'ppo'],\n",
    "    )\\\n",
    "    .resources(num_gpus=0)\\\n",
    "    .framework('torch')\n",
    ")\n",
    "trainer = config.build(env=\"poker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start up tensorboard\n",
    "#!tensorboard --logdir=~/ray_results --host 0.0.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop, each run will rollout x timesteps (where x is train_batch_size). An weight update is then applied using the rollout data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saves a checkpoint of the trainer.\n",
    "trainer.save(\"checkpoint/ppo_poker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "03af9a79c2dca760cc1a7eb3ed3e88bcac6dcfea843cc60b832e817055251c13"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
